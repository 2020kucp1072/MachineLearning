{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WpoBoSbsWb3Z"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, accuracy_score,confusion_matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "LOAD THE DATASET"
      ],
      "metadata": {
        "id": "UxiAqAQoYDIE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset with the correct delimiter\n",
        "url = \"https://drive.google.com/uc?id=1E0EURgsF3L9Bt5hnOalE0d4Tw9mIOgTn\"\n",
        "data = pd.read_csv(url, delimiter=\";\")  # Specify the delimiter as ';'\n"
      ],
      "metadata": {
        "id": "rKla_mN3Wlo0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "STRUCTURE OF THE DATASET"
      ],
      "metadata": {
        "id": "avl9d1l4YOG-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Check the structure of the dataset\n",
        "print(data.info())\n",
        "print(data.head())"
      ],
      "metadata": {
        "id": "__yyFGxeWmN2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "LABELENCODING"
      ],
      "metadata": {
        "id": "I6aIW5cnYq1D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocessing\n",
        "data = data.dropna()  # Drop rows with missing values\n",
        "label_encoder = LabelEncoder()\n",
        "for column in data.select_dtypes(include=['object']).columns:\n",
        "    data[column] = label_encoder.fit_transform(data[column])"
      ],
      "metadata": {
        "id": "2J4bmKhrWnTt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "X AND Y FOR TRAINING AND TESTING"
      ],
      "metadata": {
        "id": "9GmM_QStY-fj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Now 'y' will be a proper column, and you can split features and target\n",
        "X = data.drop(\"y\", axis=1)  # 'y' is the target column\n",
        "y = data[\"y\"]"
      ],
      "metadata": {
        "id": "se66qvlhWn28"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "SPLITTING THE DATA"
      ],
      "metadata": {
        "id": "ueTWTCmBZSt7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "J7IPjgPVWob8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "FEATURE SCALING"
      ],
      "metadata": {
        "id": "vIakAT-hZr9S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Scale the data\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n"
      ],
      "metadata": {
        "id": "U8b7Z6y1WpBB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "TRAINING THE MODEL"
      ],
      "metadata": {
        "id": "m8c_m9tfZalt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Train Logistic Regression Model\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "DlMpTWDMWpiF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "PREDICTION"
      ],
      "metadata": {
        "id": "tyPKlDOZZecY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Make Predictions\n",
        "y_pred = model.predict(X_test)"
      ],
      "metadata": {
        "id": "_Z_J2eHAZfTy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "EVALUATING THE MODEL"
      ],
      "metadata": {
        "id": "6CDSq99UZjix"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Evaluate Model\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"Confusion matix\", confusion_matrix(y_test,y_pred))\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e2Il7gIWZj7C",
        "outputId": "c739fcf7-6a34-417b-dcf7-c02a32c04c02"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.8939226519337017\n",
            "Confusion matix [[791  16]\n",
            " [ 80  18]]\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.98      0.94       807\n",
            "           1       0.53      0.18      0.27        98\n",
            "\n",
            "    accuracy                           0.89       905\n",
            "   macro avg       0.72      0.58      0.61       905\n",
            "weighted avg       0.87      0.89      0.87       905\n",
            "\n"
          ]
        }
      ]
    }
  ]
}